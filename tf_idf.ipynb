{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-idf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO26COdpRFWvLF5FVZOcfHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KMR-86/ml-test-processing-basic/blob/master/tf_idf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrb5QN9gwZEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "986234e3-1a35-4c6d-f113-e292685aa9ae"
      },
      "source": [
        "s=[\"hello would you like a cup of coffee with me\", \"bangladesh is the 2nd largest producer of coffee\",\"do you want to have some coffee with me\"]\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer=TfidfVectorizer()\n",
        "tfidf=vectorizer.fit_transform(s)\n",
        "print(tfidf)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 10)\t0.2946441102231503\n",
            "  (0, 17)\t0.2946441102231503\n",
            "  (0, 2)\t0.22881743601674914\n",
            "  (0, 11)\t0.2946441102231503\n",
            "  (0, 3)\t0.38742159665471454\n",
            "  (0, 9)\t0.38742159665471454\n",
            "  (0, 19)\t0.2946441102231503\n",
            "  (0, 18)\t0.38742159665471454\n",
            "  (0, 6)\t0.38742159665471454\n",
            "  (1, 12)\t0.3799446164315741\n",
            "  (1, 8)\t0.3799446164315741\n",
            "  (1, 0)\t0.3799446164315741\n",
            "  (1, 14)\t0.3799446164315741\n",
            "  (1, 7)\t0.3799446164315741\n",
            "  (1, 1)\t0.3799446164315741\n",
            "  (1, 2)\t0.22440141104916914\n",
            "  (1, 11)\t0.28895767404089806\n",
            "  (2, 13)\t0.3757162113174268\n",
            "  (2, 5)\t0.3757162113174268\n",
            "  (2, 15)\t0.3757162113174268\n",
            "  (2, 16)\t0.3757162113174268\n",
            "  (2, 4)\t0.3757162113174268\n",
            "  (2, 10)\t0.28574186296253085\n",
            "  (2, 17)\t0.28574186296253085\n",
            "  (2, 2)\t0.221904046872743\n",
            "  (2, 19)\t0.28574186296253085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LJ9JrSy6AYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl_QMC_hxTj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "1c47b151-0dcf-4c75-b250-79854b892ff6"
      },
      "source": [
        "print(vectorizer.get_feature_names())\n",
        "print(tfidf.toarray())\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['2nd', 'bangladesh', 'coffee', 'cup', 'do', 'have', 'hello', 'is', 'largest', 'like', 'me', 'of', 'producer', 'some', 'the', 'to', 'want', 'with', 'would', 'you']\n",
            "[[0.         0.         0.22881744 0.3874216  0.         0.\n",
            "  0.3874216  0.         0.         0.3874216  0.29464411 0.29464411\n",
            "  0.         0.         0.         0.         0.         0.29464411\n",
            "  0.3874216  0.29464411]\n",
            " [0.37994462 0.37994462 0.22440141 0.         0.         0.\n",
            "  0.         0.37994462 0.37994462 0.         0.         0.28895767\n",
            "  0.37994462 0.         0.37994462 0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.22190405 0.         0.37571621 0.37571621\n",
            "  0.         0.         0.         0.         0.28574186 0.\n",
            "  0.         0.37571621 0.         0.37571621 0.37571621 0.28574186\n",
            "  0.         0.28574186]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMwiKx_UxpNE",
        "colab_type": "text"
      },
      "source": [
        "Similar structure , just like BOW of countVectorizer. But the cells are filled up with tf-idf of words. Not the direct count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1534qNyx3cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "981f037e-6b4a-4400-e009-585bf9e698a2"
      },
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "mat=tfidf.todense()\n",
        "for m in mat:\n",
        "  print(euclidean_distances(mat[0],m))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]]\n",
            "[[1.31416389]]\n",
            "[[1.18037961]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdHsStex6BYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6c42cac-d23b-41d5-8224-46597372f42b"
      },
      "source": [
        "vectorizer12=TfidfVectorizer(ngram_range=(1,2))\n",
        "tfidf12=vectorizer12.fit_transform(s)\n",
        "print(tfidf12)\n",
        "print(vectorizer12.get_feature_names())\n",
        "print(tfidf12.toarray())\n",
        "\n",
        "mat12=tfidf12.todense()\n",
        "for m in mat12:\n",
        "  print(euclidean_distances(mat12[0],m))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 34)\t0.20777823455097327\n",
            "  (0, 5)\t0.20777823455097327\n",
            "  (0, 22)\t0.20777823455097327\n",
            "  (0, 7)\t0.2732034090851856\n",
            "  (0, 19)\t0.2732034090851856\n",
            "  (0, 38)\t0.2732034090851856\n",
            "  (0, 36)\t0.2732034090851856\n",
            "  (0, 13)\t0.2732034090851856\n",
            "  (0, 20)\t0.20777823455097327\n",
            "  (0, 33)\t0.20777823455097327\n",
            "  (0, 4)\t0.16135833448031003\n",
            "  (0, 21)\t0.20777823455097327\n",
            "  (0, 6)\t0.2732034090851856\n",
            "  (0, 18)\t0.2732034090851856\n",
            "  (0, 37)\t0.20777823455097327\n",
            "  (0, 35)\t0.2732034090851856\n",
            "  (0, 12)\t0.2732034090851856\n",
            "  (1, 24)\t0.2721088304549909\n",
            "  (1, 17)\t0.2721088304549909\n",
            "  (1, 1)\t0.2721088304549909\n",
            "  (1, 28)\t0.2721088304549909\n",
            "  (1, 15)\t0.2721088304549909\n",
            "  (1, 3)\t0.2721088304549909\n",
            "  (1, 23)\t0.2721088304549909\n",
            "  (1, 16)\t0.2721088304549909\n",
            "  (1, 0)\t0.2721088304549909\n",
            "  (1, 27)\t0.2721088304549909\n",
            "  (1, 14)\t0.2721088304549909\n",
            "  (1, 2)\t0.2721088304549909\n",
            "  (1, 22)\t0.20694577928944996\n",
            "  (1, 4)\t0.16071185870858612\n",
            "  (1, 21)\t0.20694577928944996\n",
            "  (2, 26)\t0.26499179703671394\n",
            "  (2, 11)\t0.26499179703671394\n",
            "  (2, 30)\t0.26499179703671394\n",
            "  (2, 32)\t0.26499179703671394\n",
            "  (2, 39)\t0.26499179703671394\n",
            "  (2, 9)\t0.26499179703671394\n",
            "  (2, 25)\t0.26499179703671394\n",
            "  (2, 10)\t0.26499179703671394\n",
            "  (2, 29)\t0.26499179703671394\n",
            "  (2, 31)\t0.26499179703671394\n",
            "  (2, 8)\t0.26499179703671394\n",
            "  (2, 34)\t0.2015330919300884\n",
            "  (2, 5)\t0.2015330919300884\n",
            "  (2, 20)\t0.2015330919300884\n",
            "  (2, 33)\t0.2015330919300884\n",
            "  (2, 4)\t0.1565084241223954\n",
            "  (2, 37)\t0.2015330919300884\n",
            "['2nd', '2nd largest', 'bangladesh', 'bangladesh is', 'coffee', 'coffee with', 'cup', 'cup of', 'do', 'do you', 'have', 'have some', 'hello', 'hello would', 'is', 'is the', 'largest', 'largest producer', 'like', 'like cup', 'me', 'of', 'of coffee', 'producer', 'producer of', 'some', 'some coffee', 'the', 'the 2nd', 'to', 'to have', 'want', 'want to', 'with', 'with me', 'would', 'would you', 'you', 'you like', 'you want']\n",
            "[[0.         0.         0.         0.         0.16135833 0.20777823\n",
            "  0.27320341 0.27320341 0.         0.         0.         0.\n",
            "  0.27320341 0.27320341 0.         0.         0.         0.\n",
            "  0.27320341 0.27320341 0.20777823 0.20777823 0.20777823 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.20777823 0.20777823 0.27320341\n",
            "  0.27320341 0.20777823 0.27320341 0.        ]\n",
            " [0.27210883 0.27210883 0.27210883 0.27210883 0.16071186 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.27210883 0.27210883 0.27210883 0.27210883\n",
            "  0.         0.         0.         0.20694578 0.20694578 0.27210883\n",
            "  0.27210883 0.         0.         0.27210883 0.27210883 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.15650842 0.20153309\n",
            "  0.         0.         0.2649918  0.2649918  0.2649918  0.2649918\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.20153309 0.         0.         0.\n",
            "  0.         0.2649918  0.2649918  0.         0.         0.2649918\n",
            "  0.2649918  0.2649918  0.2649918  0.20153309 0.20153309 0.\n",
            "  0.         0.20153309 0.         0.2649918 ]]\n",
            "[[1.49011612e-08]]\n",
            "[[1.33271913]]\n",
            "[[1.23723491]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}